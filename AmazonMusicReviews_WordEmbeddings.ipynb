{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmazonMusicReviews_WordEmbeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0iDQ6lKKTRMsavQGFgtAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeedas/Musicreviews/blob/master/AmazonMusicReviews_WordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQFAUDKr-JgC",
        "colab_type": "text"
      },
      "source": [
        "This notebook is to learn about the word embeddings. In the notebook we try sentiment analysis with the amazon music reviews dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJhXPe-_-uli",
        "colab_type": "text"
      },
      "source": [
        "Connect to the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm3UACof93ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZA_CvZu-5DW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1a77848-8517-4183-a7d4-18d2f2ff5e1f"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8jymPzN_ka2",
        "colab_type": "text"
      },
      "source": [
        "Connect to the project files on the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUO54gFzncQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/DLCP/NLP/\"\n",
        "Reviews_path = \"/content/drive/My Drive/MyDrive/Amazonreviews/Musicreviews/\"\n",
        "GLOVE_PATH = \"/content/drive/My Drive/Fake News Challenge/\"\n",
        "#/content/drive/My Drive/MyDrive/Amazonreviews/Musicreviews/573774_1043123_bundle_archive.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjqjeRp_nkEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJo1YiRjx3FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile(GLOVE_PATH+'glove.6B.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93fSZQmb96Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile(Reviews_path+'573774_1043123_bundle_archive.zip', 'r') as y:\n",
        "  y.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m0VXn5o_s7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "88e83f8d-5e97-42d4-bf12-ef2a1892f79e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.300d.txt\t       Musical_instruments_reviews.csv\n",
            "glove.6B.100d.txt  glove.6B.50d.txt\t       sample_data\n",
            "glove.6B.200d.txt  Musical_Instruments_5.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-bFOWAQd1B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6avCX96QO26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvBtsADefbtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Dropout,Activation\n",
        "from keras.layers import Flatten,Input\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import concatenate\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "\n",
        "from IPython.display import SVG\n",
        "#from keras.utils import model_to_dot\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGEDS0rOQAha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_mr = pd.read_csv(\"./Musical_instruments_reviews.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STA1OeaLQf7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "b4db7554-c447-448f-dc81-4df43e13036f"
      },
      "source": [
        "print(df_mr.head())\n",
        "print(df_mr.columns)\n",
        "print(df_mr.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       reviewerID  ...                                             review\n",
            "0  A2IBPI20UZIR0U  ...  Not much to write about here, but it does exac...\n",
            "1  A14VAT5EAX3D9S  ...  The product does exactly as it should and is q...\n",
            "2  A195EZSQDW3E21  ...  The primary job of this device is to block the...\n",
            "3  A2C00NNG1ZQQG2  ...  Nice windscreen protects my MXL mic and preven...\n",
            "4   A94QU4C90B1AX  ...  This pop filter is great. It looks and perform...\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
            "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'review'],\n",
            "      dtype='object')\n",
            "(10261, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVb4kJLcRZg-",
        "colab_type": "text"
      },
      "source": [
        "Check the empty values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VccKMPexReUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "18798ee0-0fc3-4871-d1c7-c7819840512e"
      },
      "source": [
        "df_mr.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "reviewerID         0\n",
              "asin               0\n",
              "reviewerName      27\n",
              "helpful            0\n",
              "reviewText         7\n",
              "overall            0\n",
              "summary            0\n",
              "unixReviewTime     0\n",
              "reviewTime         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLsCR4DARvZ-",
        "colab_type": "text"
      },
      "source": [
        "Fill the na in review text with blank space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne8wIwCOR2uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_mr.reviewText.fillna(\" \",inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP1AYTt6Spr1",
        "colab_type": "text"
      },
      "source": [
        "Merge review text and summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSvxhc92Suoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_review = df_mr['reviewText'] + df_mr['summary']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDiaDI-ZTIMg",
        "colab_type": "text"
      },
      "source": [
        "Consider the sentiment depending on overall rating. If overall rating is 0,1,2,3 then we take it as negative and put as 0 but if rating is 4 or 5 we take as positive and put as 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X42oSyL2VupB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fc395a09-7f81-43af-84a4-a49d0c492740"
      },
      "source": [
        "df_mr.overall.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    6938\n",
              "4.0    2084\n",
              "3.0     772\n",
              "2.0     250\n",
              "1.0     217\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P39BSK7CUOZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment(value):\n",
        "  if (int(value) == 1 or int(value) == 2 or int(value) == 3):\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "df_mr.overall  = df_mr.overall.apply(sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmhZ4v4BVSHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "583733ea-03e2-4d1b-809c-f4ca0973f43a"
      },
      "source": [
        "df_mr.overall.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    9022\n",
              "0    1239\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoqLbV031Lix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(count, col) = df_mr.shape\n",
        "texts = []\n",
        "for i in range (0, count):\n",
        "  texts.append(df_review[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "338bT23xdS_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = 40000\n",
        "MAX_SEQUENCE_LENGTH = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ5MYMIcdWmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "274ad9e4-049c-45f5-c78e-04c0979d042b"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 22813 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhesXjdAoR7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(df_mr.overall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7O5zgk155hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "y = to_categorical(np.asarray(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGx060FcoVDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state = 40)\n",
        "\n",
        "[nSamp,inpShape] = X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8RPn8uqoYBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "38d86b32-4ddc-4499-9d15-93d266d5434a"
      },
      "source": [
        "print(\"X train shape \",X_train.shape)\n",
        "print(\"X test shape \",X_test.shape)\n",
        "print(\"y train shape \",y_train.shape)\n",
        "print(\"y test shape \",y_test.shape)\n",
        "\n",
        "print(nSamp,inpShape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape  (8208, 100)\n",
            "X test shape  (2053, 100)\n",
            "y train shape  (8208, 2)\n",
            "y test shape  (2053, 2)\n",
            "8208 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFMT848fR4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4ffd298f-84d2-45e3-e815-e108ae8e01e2"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('./glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "vocab = tokenizer.sequences_to_texts(texts)\n",
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print (vocab_size)\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n",
            "22814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SqVJIdUf8Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cb66f2f-9d95-475c-eb3b-e55828e89865"
      },
      "source": [
        "# Add sequential model\n",
        "sentiment_model = Sequential()\n",
        "# Add embedding layer \n",
        "#No of output dimenstions is 100 as we embedded with Glove 100d\n",
        "Embed_Layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=(MAX_SEQUENCE_LENGTH,), trainable=True)\n",
        "#define Inputs\n",
        "review_input = Input(shape=(MAX_SEQUENCE_LENGTH,),dtype= 'int32',name = 'review_input')\n",
        "review_embedding = Embed_Layer(review_input)\n",
        "Flatten_Layer = Flatten()\n",
        "review_flatten = Flatten_Layer(review_embedding)\n",
        "output_size = 2\n",
        "\n",
        "dense1 = Dense(100,activation='relu')(review_flatten)\n",
        "\n",
        "dense2 = Dense(32,activation='relu')(dense1)\n",
        "predict = Dense(2,activation='softmax')(dense2)\n",
        "\n",
        "sentiment_model = Model(inputs=[review_input],outputs=[predict])\n",
        "sentiment_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "print(sentiment_model.summary())\n",
        "\n",
        "SVG(model_to_dot(sentiment_model).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "review_input (InputLayer)    [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 100, 100)          2281400   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               1000100   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 3,284,798\n",
            "Trainable params: 3,284,798\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"547pt\" viewBox=\"0.00 0.00 179.00 410.00\" width=\"239pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 406)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 175,-406 175,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140338209552648 -->\n<g class=\"node\" id=\"node1\">\n<title>140338209552648</title>\n<polygon fill=\"none\" points=\"3.5,-365.5 3.5,-401.5 167.5,-401.5 167.5,-365.5 3.5,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-379.8\">review_input: InputLayer</text>\n</g>\n<!-- 140338210145728 -->\n<g class=\"node\" id=\"node2\">\n<title>140338210145728</title>\n<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 171,-328.5 171,-292.5 0,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-306.8\">embedding_5: Embedding</text>\n</g>\n<!-- 140338209552648&#45;&gt;140338210145728 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140338209552648-&gt;140338210145728</title>\n<path d=\"M85.5,-365.4551C85.5,-357.3828 85.5,-347.6764 85.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-338.5903 85.5,-328.5904 82.0001,-338.5904 89.0001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140338209552928 -->\n<g class=\"node\" id=\"node3\">\n<title>140338209552928</title>\n<polygon fill=\"none\" points=\"29,-219.5 29,-255.5 142,-255.5 142,-219.5 29,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-233.8\">flatten_2: Flatten</text>\n</g>\n<!-- 140338210145728&#45;&gt;140338209552928 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140338210145728-&gt;140338209552928</title>\n<path d=\"M85.5,-292.4551C85.5,-284.3828 85.5,-274.6764 85.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-265.5903 85.5,-255.5904 82.0001,-265.5904 89.0001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140338209535536 -->\n<g class=\"node\" id=\"node4\">\n<title>140338209535536</title>\n<polygon fill=\"none\" points=\"28.5,-146.5 28.5,-182.5 142.5,-182.5 142.5,-146.5 28.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-160.8\">dense_10: Dense</text>\n</g>\n<!-- 140338209552928&#45;&gt;140338209535536 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140338209552928-&gt;140338209535536</title>\n<path d=\"M85.5,-219.4551C85.5,-211.3828 85.5,-201.6764 85.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-192.5903 85.5,-182.5904 82.0001,-192.5904 89.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140338209534472 -->\n<g class=\"node\" id=\"node5\">\n<title>140338209534472</title>\n<polygon fill=\"none\" points=\"29,-73.5 29,-109.5 142,-109.5 142,-73.5 29,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-87.8\">dense_11: Dense</text>\n</g>\n<!-- 140338209535536&#45;&gt;140338209534472 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140338209535536-&gt;140338209534472</title>\n<path d=\"M85.5,-146.4551C85.5,-138.3828 85.5,-128.6764 85.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-119.5903 85.5,-109.5904 82.0001,-119.5904 89.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140338209603424 -->\n<g class=\"node\" id=\"node6\">\n<title>140338209603424</title>\n<polygon fill=\"none\" points=\"28.5,-.5 28.5,-36.5 142.5,-36.5 142.5,-.5 28.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-14.8\">dense_12: Dense</text>\n</g>\n<!-- 140338209534472&#45;&gt;140338209603424 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140338209534472-&gt;140338209603424</title>\n<path d=\"M85.5,-73.4551C85.5,-65.3828 85.5,-55.6764 85.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-46.5903 85.5,-36.5904 82.0001,-46.5904 89.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CqoEzgq5c9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "0070a788-c6ce-43dd-f701-53fd69aadcb1"
      },
      "source": [
        "sentiment_model.fit(X_train,y_train,epochs= 5,batch_size=32,verbose=True,validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "257/257 [==============================] - 10s 37ms/step - loss: 0.3765 - acc: 0.8653 - val_loss: 0.2919 - val_acc: 0.8846\n",
            "Epoch 2/5\n",
            "257/257 [==============================] - 9s 36ms/step - loss: 0.1977 - acc: 0.9224 - val_loss: 0.2931 - val_acc: 0.8758\n",
            "Epoch 3/5\n",
            "257/257 [==============================] - 10s 37ms/step - loss: 0.0805 - acc: 0.9719 - val_loss: 0.3448 - val_acc: 0.8695\n",
            "Epoch 4/5\n",
            "257/257 [==============================] - 9s 37ms/step - loss: 0.0177 - acc: 0.9961 - val_loss: 0.5132 - val_acc: 0.8919\n",
            "Epoch 5/5\n",
            "257/257 [==============================] - 9s 36ms/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.5185 - val_acc: 0.8831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa309202668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR-ZGGSPoKPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "bb1633ea-0b3b-4f2f-ad3a-dedbcedfc76e"
      },
      "source": [
        "!pip install wget\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=dcefd0fc9102616632c76dcd3ad0e136be3337c189e034f4fb03cb4903a86dbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "--2020-09-23 13:13:07--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.16.118\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.16.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  36.0MB/s    in 44s     \n",
            "\n",
            "2020-09-23 13:13:52 (35.3 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zteW06lbmPCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7b0ec8cd-a20b-4a6e-afa8-20d00515570a"
      },
      "source": [
        "#Using word2vec\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "embeddings_wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "embeddings_wv.init_sims(replace=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSXhoVguZq0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "17cd3637-90a4-4652-9879-e33e7c109e67"
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "embeddings_wv = KeyedVectors.load_word2vec_format(datapath('word2vec_pre_kv_c'), binary=False)  # C text format\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(datapath(\"euclidean_vectors.bin\"), binary=True)  # C bin format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTGNoqqgwpac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7ed3398b-a2e8-4ce0-ab47-3d190d1b3ae5"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "embeddings_ap = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw1viOOPmvXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46eda787-9fb7-4b80-d0e0-5433c78a0f92"
      },
      "source": [
        "vocab = tokenizer.sequences_to_texts(texts)\n",
        "\n",
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print (vocab_size)\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\ttry:\n",
        "\t\tembedding_vector = embeddings_ap[word]\n",
        "\t\tif embedding_vector is not None:\n",
        "\t\t\tembedding_matrix[i] = embedding_vector\n",
        "\texcept:\n",
        "\t\tpass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka179OtqwdzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ef15f77-2fec-472f-eac7-0265f23c3dbe"
      },
      "source": [
        "sentiment_wv_model = Sequential()\n",
        "# Add embedding layer \n",
        "#No of output dimenstions is 100 as we embedded with Word2Vec 100d\n",
        "Embed_Layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=(MAX_SEQUENCE_LENGTH,), trainable=True)\n",
        "\n",
        "#define Inputs\n",
        "review_input = Input(shape=(MAX_SEQUENCE_LENGTH,),dtype= 'int32',name = 'review_input')\n",
        "review_embedding = Embed_Layer(review_input)\n",
        "Flatten_Layer = Flatten()\n",
        "review_flatten = Flatten_Layer(review_embedding)\n",
        "output_size = 2\n",
        "\n",
        "dense1 = Dense(100,activation='relu')(review_flatten)\n",
        "dense2 = Dense(32,activation='relu')(dense1)\n",
        "predict = Dense(2,activation='softmax')(dense2)\n",
        "\n",
        "sentiment_wv_model = Model(inputs=[review_input],outputs=[predict])\n",
        "sentiment_wv_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "print(sentiment_wv_model.summary())\n",
        "SVG(model_to_dot(sentiment_wv_model).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "review_input (InputLayer)    [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 100, 100)          2281400   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               1000100   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 3,284,798\n",
            "Trainable params: 3,284,798\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"547pt\" viewBox=\"0.00 0.00 179.00 410.00\" width=\"239pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 406)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 175,-406 175,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140369732054432 -->\n<g class=\"node\" id=\"node1\">\n<title>140369732054432</title>\n<polygon fill=\"none\" points=\"3.5,-365.5 3.5,-401.5 167.5,-401.5 167.5,-365.5 3.5,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-379.8\">review_input: InputLayer</text>\n</g>\n<!-- 140369732048096 -->\n<g class=\"node\" id=\"node2\">\n<title>140369732048096</title>\n<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 171,-328.5 171,-292.5 0,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-306.8\">embedding_2: Embedding</text>\n</g>\n<!-- 140369732054432&#45;&gt;140369732048096 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140369732054432-&gt;140369732048096</title>\n<path d=\"M85.5,-365.4551C85.5,-357.3828 85.5,-347.6764 85.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-338.5903 85.5,-328.5904 82.0001,-338.5904 89.0001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140369732054712 -->\n<g class=\"node\" id=\"node3\">\n<title>140369732054712</title>\n<polygon fill=\"none\" points=\"29,-219.5 29,-255.5 142,-255.5 142,-219.5 29,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-233.8\">flatten_2: Flatten</text>\n</g>\n<!-- 140369732048096&#45;&gt;140369732054712 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140369732048096-&gt;140369732054712</title>\n<path d=\"M85.5,-292.4551C85.5,-284.3828 85.5,-274.6764 85.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-265.5903 85.5,-255.5904 82.0001,-265.5904 89.0001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140368390765816 -->\n<g class=\"node\" id=\"node4\">\n<title>140368390765816</title>\n<polygon fill=\"none\" points=\"32,-146.5 32,-182.5 139,-182.5 139,-146.5 32,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-160.8\">dense_6: Dense</text>\n</g>\n<!-- 140369732054712&#45;&gt;140368390765816 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140369732054712-&gt;140368390765816</title>\n<path d=\"M85.5,-219.4551C85.5,-211.3828 85.5,-201.6764 85.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-192.5903 85.5,-182.5904 82.0001,-192.5904 89.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140368390765368 -->\n<g class=\"node\" id=\"node5\">\n<title>140368390765368</title>\n<polygon fill=\"none\" points=\"32,-73.5 32,-109.5 139,-109.5 139,-73.5 32,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-87.8\">dense_7: Dense</text>\n</g>\n<!-- 140368390765816&#45;&gt;140368390765368 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140368390765816-&gt;140368390765368</title>\n<path d=\"M85.5,-146.4551C85.5,-138.3828 85.5,-128.6764 85.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-119.5903 85.5,-109.5904 82.0001,-119.5904 89.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140368390799992 -->\n<g class=\"node\" id=\"node6\">\n<title>140368390799992</title>\n<polygon fill=\"none\" points=\"32,-.5 32,-36.5 139,-36.5 139,-.5 32,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-14.8\">dense_8: Dense</text>\n</g>\n<!-- 140368390765368&#45;&gt;140368390799992 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140368390765368-&gt;140368390799992</title>\n<path d=\"M85.5,-73.4551C85.5,-65.3828 85.5,-55.6764 85.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"89.0001,-46.5903 85.5,-36.5904 82.0001,-46.5904 89.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-L1xzByTZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "89d7a497-6c9f-42d6-f978-77de3c7d55b2"
      },
      "source": [
        "sentiment_wv_model.fit(X_train,y_train,epochs= 5,batch_size=32,verbose=True,validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "257/257 [==============================] - 7s 26ms/step - loss: 0.3696 - acc: 0.8756 - val_loss: 0.2962 - val_acc: 0.8914\n",
            "Epoch 2/5\n",
            "257/257 [==============================] - 6s 24ms/step - loss: 0.2088 - acc: 0.9183 - val_loss: 0.2787 - val_acc: 0.8831\n",
            "Epoch 3/5\n",
            "257/257 [==============================] - 6s 24ms/step - loss: 0.0788 - acc: 0.9732 - val_loss: 0.3806 - val_acc: 0.8782\n",
            "Epoch 4/5\n",
            "257/257 [==============================] - 6s 24ms/step - loss: 0.0189 - acc: 0.9952 - val_loss: 0.4651 - val_acc: 0.8855\n",
            "Epoch 5/5\n",
            "257/257 [==============================] - 6s 25ms/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.5484 - val_acc: 0.8894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa100a7b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCeCyRUAobJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rom keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Create a Model\n",
        "model_cV = Sequential([\n",
        "  Dense(64, activation='relu', input_shape=(inpShape,)),\n",
        "  Dense(32, activation='relu'),\n",
        "  Dense(2, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model_cV.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAEhx9xwod42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model.\n",
        "model_cV.fit(\n",
        "  X_train,\n",
        "  to_categorical(y_train),\n",
        "  epochs=5,\n",
        "  batch_size=32,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIcEmh4uogmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cV.evaluate(\n",
        "  X_test,\n",
        "  to_categorical(y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bGhwQibojOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict on the first 5 test messages.\n",
        "predictions = model_cV.predict(X_test[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(y_test[:5]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAFE4KWoomD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model_cV.summary())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}